:PROPERTIES:
:TOC:      :include all :force (depth) :ignore (this) :local (depth)
:END:
#+TITLE: SysAdmin Cookbook

Here is a collection of neat aliases, scripts, shell-isms, tips, and tricks of the trade that I've found useful in navigating the unix-sphere over the years.

* Table of Content
:PROPERTIES:
:TOC:      :include all :force (depth) :ignore (this) :local (depth)
:END:
:CONTENTS:
- [[#shell-scripting][Shell Scripting]]
  - [[#debugging][Debugging]]
  - [[#reuse-arguments-][Reuse arguments (!$)]]
  - [[#last-exit-code-][Last Exit Code ($?)]]
  - [[#-curly-brace-expansion-][{ Curly Brace Expansion }]]
  - [[#ez-backup-with-cp-or-rsync][EZ backup with cp (or rsync)]]
  - [[#repeat-command][Repeat command]]
  - [[#streams][Streams]]
    - [[#stderr][stderr]]
    - [[#stdout--stderr][stdout & stderr]]
  - [[#substrings][Substrings]]
- [[#useful-programs][Useful programs]]
  - [[#trash-cli][trash-cli]]
  - [[#coreutil-replacements][Coreutil replacements]]
- [[#common-cli-utilities][Common CLI Utilities]]
  - [[#cut][cut]]
    - [[#cut---list-all-users][cut - List all users]]
  - [[#awk][awk]]
    - [[#simple-field-column-print][Simple field (column) print]]
    - [[#print-lines-matching-regex][Print lines matching regex]]
  - [[#sed][sed]]
    - [[#multiple-expressions][Multiple expressions]]
    - [[#scripting-sed][Scripting sed]]
      - [[#file][File]]
      - [[#command][Command]]
  - [[#awksed][awk/sed]]
  - [[#find][find]]
    - [[#search-for-files-older-than-7-days-and-delete-them][Search for files older than 7 days (and delete them)]]
  - [[#du][du]]
  - [[#sort][sort]]
    - [[#sort-unique-occurences-of-a-line-in-a-file][Sort unique occurences of a line in a file]]
  - [[#dmidecodelshw][dmidecode/lshw]]
- [[#permissions][Permissions]]
  - [[#umask][Umask]]
- [[#networking][Networking]]
  - [[#check-if-remote-port-is-open][Check if remote port is open]]
  - [[#check-isp-ip][Check ISP IP]]
  - [[#bonding-methods][Bonding Methods]]
  - [[#http-method-binaries][HTTP Method Binaries]]
  - [[#check-sites-http-method-whitelist][Check sites HTTP method whitelist]]
- [[#sql][SQL]]
  - [[#installation][Installation]]
  - [[#files][Files]]
  - [[#logs][Logs]]
  - [[#general][General]]
  - [[#create-user][Create User]]
- [[#journalctl][journalctl]]
- [[#systemd][systemd]]
  - [[#useful-commands][Useful commands]]
  - [[#run-level-management][Run level management]]
  - [[#unit-file-reference][Unit File Reference]]
    - [[#service-unit-files][Service Unit Files]]
    - [[#mount-unit-files][Mount Unit Files]]
    - [[#socket-unit-file][Socket Unit File]]
  - [[#systemd-status][Systemd Status]]
- [[#cronatd][cron/atd]]
  - [[#cron][cron]]
  - [[#atd][atd]]
- [[#apachehttpd][apache/httpd]]
  - [[#troubleshooting][Troubleshooting]]
- [[#nginx][nginx]]
  - [[#security-reference][Security Reference]]
  - [[#load-balancer-reference][Load Balancer Reference]]
  - [[#reverse-proxy-reference][Reverse Proxy Reference]]
- [[#scripts][Scripts]]
  - [[#ls--la-with-numerical-file-permissionsmode][ls -la with numerical file permissions/mode]]
- [[#misc][Misc]]
- [[#reference][Reference]]
- [[#notes][Notes]]
:END:
  
* Shell Scripting
** Debugging
#+begin_src shell
/usr/bin/env bash
set -xv
#+end_src
** wildcarding through nested directories
In order to wildcard through nested directories, we use the =**= glob.
#+begin_src shell
# This will sed replace all occurences of an extension with the basename of the file without the extension recusively through nested directories.
rename 's/\..*//.' **
#+end_src
** for loops
#+begin_src shell
for i in ./*; do file $i; done
#+end_src
** Reuse arguments (!$)
#+begin_src shell
$ ls /tmp
file1.txt file2.txt file3.txt
$ cd !$
/tmp
#+end_src
** $0 expands to your your shell (/bin/sh, /bin/bash)
** Last Exit Code ($?)
#+begin_src shell
$ ls /tmp
file1.txt
$ echo $?
0
#+end_src
** { Curly Brace Expansion }
{ curly brace expansion } can be useful when you run a series of similar commands that differ. Acts as a mini =for= loop.
  #+begin_src shell
  $ touch file-{1,2,3}.md
  $ ls
  # Creates file-1.md file-2.md file-3.md
  #+end_src
** EZ backup with cp (or rsync)
#+begin_src shell
$ cp file.txt{,.bak}
$ ls -l
file.txt
file.txt.bak
#+end_src
** Repeat command
Execute a command every two seconds and monitor output.
#+begin_src shell
watch -n2 echo hello
#+end_src

** Streams
Because for some reason I forget them all the time
*** stderr
#+begin_src shell
$ >&2 echo hello
#+end_src
*** stdout & stderr
#+begin_src shell
$ 1>&2 echo hello
#+end_src
** Substrings
Hash =#= will find the first occurence from the start, and modulo =%= will grab the first occurence from the end. =*= for mc-globbin'. If you're feeling greedy, =##= and =%%=.
#+begin_src shell
$ var="death metal"

$ echo ${var#* } # Get second word
metal
$ echo ${var#*d} # Cuts specified substring
eath metal
$ echo ${var##*t} # Cuts everything up until the matched char
al

$ echo ${var% *} # Get first word
death
$ echo ${var%a*} # Cuts specified substring starting from end
death met
$ echo ${var%%a*} # Cuts after occurence
de
#+end_src
* CLI Utilities
** cut
*** cut - List all users
#+begin_src shell
$ cut -d: -f1 /etc/passwd
#+end_src
** grep
- To grep through binary files as if they were text:
#+begin_src shell
grep -a 'pattern' data.txt

# Alternatively
strings data.txt | grep -E 'pattern'
#+end_src

- To only print filenames (and not their content) that match a string
#+begin_src shell
grep -lR string
#+end_src
** awk
- =-F=: Allows you to specify a field specifier with a delimiting character (such as comma, colon, etc). For example: =awk -F: '{ print $1 }' /etc/passwd=
- =-f=: Specify awk script file
*** Simple field (column) print
#+begin_src sh
# delimiter comes after -F
awk -F : '{print $5, $3, $8}' /etc/passwd

# You can only print fields of a regex using
awk '/systemd/ { print $1 }' /etc/passwd
#+end_src
*** Print lines matching regex
#+begin_src shell
awk '/MA/' list.txt
#+end_src
*** Add all numbers in a file
#+begin_src shell
# For every integer in sum-me.txt, we += it to sum, and then once EOF is reached, we print the variable.
awk '{ sum += $1 } END { print sum }' sum-me.txt
#+end_src
*** Print nth line
#+begin_src shell
# awk keeps a running count of lines bound to NR
cat file.txt | awk 'NR==25'
#+end_src
*** NF (Number of Fields)
NF is a predefined variable whose value is the number of fields in the current record. awk automatically updates the value of NF each time it reads a record.

This is useful when you want only values with a specific number of fields. In the case of sorting prime factorizations to only show uniqe prime numbers:
#+begin_src shell
# sort -u bunch_of_numbers.txt gives us a list of unique integers, which we then pipe to factor to get the prime factorizations, and then we tell awk via the NF variable that we only want values that have less than 3 fields which indicates that the number is prime.
sort -u bunch_of_numbers.txt | factor | awk 'NF<3'
#+end_src
** sed
- =-n=: prints only modified lines when coupled with ~/p~ at the end of the sed expression.
*** Multiple expressions
#+begin_src sh
sed -e 's/ MA/, Massachusetts/' -e 's/ PA/, Pennsylvania/' file.txt
#+end_src
*** Scripting sed
**** File
#+begin_src shell
s/ MA/, Massachusetts/
s/ PA/, Pennsylvania/
s/ CA/, California/
s/ VA/, Virginia/
s/ OK/, Oklahoma/
#+end_src
**** Command
#+begin_src shell
# Applies the script sed-script.sed to the file list.txt
sed -f sed-script.sed list.txt

# You can save the input to a new file w/
sed -f sed-script.sed list.txt > newlist.txt
#+end_src
** awk/sed
#+begin_src sh
# You can subsitute strings, and then print with awk based on the new substitutions.
# $ cat script.sed
# s/ CA/, California/
# s/ MA/, Massachusetts
sed -f script.sed list.txt | awk -F, '{ print $4 }'
# => California
# => Massachusetts
#+end_src
** find
*** Execute Commands
#+begin_src shell
# This will recusively find all files named access.log and execute grep on all files that have the string 500 in them.
find . -name access.log* -exec grep 500 {} \;
#+end_src
*** Search for files older than 7 days (and delete them)
#+begin_src shell
find /opt/neteng/mtr/reports -mtime +7 -delete
#+end_src
*** Hide permission denied files
#+begin_src shell
# Just stream stderr to /dev/null
find / -size 33 2>/dev/null
#+end_src
*** Recusively list directory contents  without leading directory path
#+begin_src shell
find . -type f -exec basename {} \;
#+end_src
** rename
#+begin_src shell
# This will sed replace all occurences of an extension with the basename of the file without the extension recusively through nested directories.
rename 's/\..*//.' **
#+end_src
** sort
*** Sort unique occurences of a line in a file
Against intuition, uniq only sorts adjacent lines, so you need to sort the file first in order to get like-strings at the top. As far as I understand it: uniq can then filter it as you'd expect it to.
#+begin_src shell
sort data.txt | uniq -u
#+end_src

If you need to sort through unique instances of an item in a file, use =sort -u= or pipe (|) =uniq=. The =-c= flag in uniq will put the count of each uniq item next to the value itself. Say, you need to sort and count unique IPs from most occuring to least occuring and returning with 200 codes:
#+begin_src shell
$ awk '{print $4, $5}' | grep 200 | sort -u # or you can pipe this to uniq -c

# => 240 192.168.1.2 200
# => 239 192.168.1.3 200
#+end_src
** seq
seq prints a sequence of numbers, but you can use it to loop over a range of numbers. Note that you can start seq with a number such as 0001.
#+begin_src shell
# This program will echo a passphrase + 4 digit pin to a server listening on a port which we are connecting to via netcat (nc)
for foo in `seq -w 0001 9999`; do
    echo "UoMYTrfrBFHyQXmg6gzctqAwOmw1IohZ $foo";
done | nc localhost 30002
#+end_src
** tr
- Decode ROT13 a.k.a. encoding where string chars are moved 13 chars forward alphabetically.
#+begin_src shell
cat data.txt | tr 'A-Za-z' 'N-ZA-Mn-za-m'
#+end_src

- Split file contents into new lines by delimiter
  #+begin_src shell
# We are using the comma as a delimiter in tr
cat file.txt | tr ',', '\n'
  #+end_src

- Remove spaces from middle of word
  #+begin_src shell
ls | tr ' ' '.'
  #+end_src
** script
=script= can start an interactive session which records terminal output and records it to a file.
#+begin_src shell
$ script
# -> creates typescript in $(pwd) with output of commands entered after starting script.
#+end_src
** GNU coreutil replacements
- =bat=: more modern =cat=, with automatic paging and syntax highlighting.
- =ripgrep=: a faster alternative to =grep=.
- =exa=: a modern replacement for =ls= with sane defaults.
- =fd=: a modern, faster replacement for =fd= with sane and intuitive defaults.
- =gdu=: interactive disk usage program with sane human readable defaults.
- =dog=: an awesome replacement for dig with much informative output. Make an alias function with:
  #+begin_src shell
dog-dig () { dog "$1" A AAAA MX NS TXT SOA }
alias dig="dog-dig"
  #+end_src
- =tldr=: outputs a summarized manual page, with common usage examples.
- =cheat=: similar to =tldr=, but outputs only common usage examples.
  =trash-cli= lets you emulate common file explorer 'Trash Can' functionality on the cli. Essential to alias this to =rm=, so you never unncecessarily/accidentally nuke a file.
  #+begin_src shell
  alias rm="trash -v --trash-dir=$HOME/.trash"
  #+end_src
** Hacks
Home to the clever outcasts
*** Print only first instance of duplicate line
#+begin_src shell
# cat -n to get numbered output, sort -uk2 to get unique sort, sort -nk1 to sort numerically preserving order, and cut to chop off cats -n.
cat -n faces.txt | sort -uk2 | sort -nk1 | cut -f2-
#+end_src

This can also be done by awk, but since I don't quite understand it fully (yet) it lives in here and not the =awk= section.
#+begin_src sh
awk '!visited[$0]++' faces.txt
#+end_src
** Misc
For interesting utilities that don't warrant their own section

*** basename - remove leading directory paths from files
Removes leading directory paths to files when listing.
#+begin_src shell
find . -type f -exec basename {} \;
#+end_src
*** dirname - lists directory path of file
#+begin_src shell
# recusively lists directories containing files with a .tf extension
dirname **/*.tf
#+end_src
*** base64 - encode/decode base64
#+begin_src shell
# Decode base64 encoding
base64 -d file.txt
#+end_src
*** tac - reverses output line by line
*** rev - reverses output char by char
* Regex
- =**= - Recursively glob
* System Administration
** Umask
Determines initial permission bits for new files. You are setting the bits that should *NOT* be set on a newly created file (otherwise known as the logical compliment).

Example
    - 027 = (7 - 0 = 7 User), (7 - 2 = 5 Group), (7 - 7 = 0 Other) = 750
    - System wide setting: ~UMASK~ in =/etc/login.defs=
    - Per User setting: users =.bashrc= with ~umask 002~ (or whatever value you'd like)

** sshd
- =sshd -t= - flag for test mode (similar to nginx -t). Will test the configuration of sshd_config.
** journalctl
=sudo journalctl -u apache2.service --since today --no-pager=: only show today logging output
** systemd
*** Useful commands
=systemctl list-unit-files | grep enabled=: Show enabled units

=systemctl --type=service=: Show only service units

=systemctl list-units --type=service --all=: Shows all active & inactive service units

=systemctl --failed --type=service=: Shows failed services

=systemctl status -l httpd.service=: Shows detailed status information

*** Run level management
=systemctl isolate=: change runlevel
=systemctl get-default=: see default runlevel
| Run Level | Target            |
|         0 | poweroff.target   |
|         1 | rescue.target     |
|         3 | multi-user.target |
|         5 | graphical.target  |
|         6 | reboot.target     |
| emergency | emergency.target  |
*** Unit File Reference
**** Service Unit Files
#+begin_src shell
[Unit]
# Describes the unit and dependencies.
Description=Vsftpd ftp daemon
After=network.target
Before=graphical.target

# Describes how to start and stop the service, and request status.
[Service]
Type=forking|oneshot
ExecStart=/usr/sbin/vsftpd /etc/vsftpd/vstpd.conf

# Describes which target this unit needs to be started in.
[Install]
WantedBy=multi-user.target
#+end_src
**** Mount Unit Files
#+begin_src shell
[Unit]
# Describes the unit and dependencies.
Description=Temporary Dir (/tmp/stuff)
Documentation=man:somemanpage
ConditionPathIsSymbolicLink=!/tmp/stuff
DefaultDependencies=no
Conflicts=umount.target
Before=local-fs.target umount.target
After=swap.target

# Describes mount properties
What=tmpfs
Where=/tmp/stuff
Type=tmpfs
Options=mode=1777,strictatime,nosuid,nodev

#+end_src
**** Socket Unit File
#+begin_src shell
[Unit]
Description=Cockpit Web Service Socket
Documentation=man:cockpit-ws(8)
Wants=cockpit-motd.service

[Socket]
# Defines tcp port that systemd should be listening to
ListenStream=9090
# For UDP
ListenDatagram=9090
ExecStartPost=-/usr/share/cockpit/motd/update-motd '' localhost
ExecStartPost=-/bin/ln -snf active.motd /run/cockpit/motd
ExecStopPost=-/bin/ln -snf /usr/share/cockpit/motd/inactive.motd /run/cockpit/motd

[Install]
WantedBy=sockets.target
#+end_src

*** Systemd Status
| Status          | Description                                                        |
| Loaded          | Unit file has been processed and unit is active                    |
| Active(running) | Running with one or more active                                    |
|                 | processes                                                          |
| Active(exited)  | Successfully completed a one-time run                              |
| Active(waiting) | Running and waiting for an event                                   |
| Inactive(dead)  | Not running                                                        |
| Enabled         | Started at boot-time                                               |
| Disabled        | Not started at boot-time                                           |
| Static          | Cannot be enabled but may be started by another unit automatically |
** cron/atd
*** cron
|Fields      |          |
|minute      |0-59      |
|hour        |0-23      |
|day-of-month|1-31      |
|month       |1-12      |
|day-of-week |0-7       |

*** atd
  Make sure atd.service is enabled and running
  =atq=: check jobs
  Examples: =at noon=, =at 14:00=
** dmidecode/lshw
=dmidecode= is nifty for finding information about hardware. You can also use =lshw= (and =grep=) to find information about your hardware as well.

#+begin_src sh
# Find SMBIOS data
$ sudo dmidecode --system
#+end_src

#+begin_src sh
# Get chassis info
$ sudo dmidecode --chassis
#+end_src

#+begin_src sh
# This will return a list of potential arguments you can use with
$ sudo dmidecode -s
#+end_src

#+begin_src sh
# To fine tune the search, enter one of the options from the returned list
$ sudo dmidecode -s bios-vendor
#+end_src
** du
#+begin_src shell
$ du -sh * | sort -h
#+end_src
* Networking
** openssl
One way to establish an SSL connection to a host and send it data over a network is the openssl command line utility, for this purpose its much better than telnet.
#+begin_src shell
$ openssl
> s_client -connect localhost:20000
#+end_src
** Check if remote port is open
#+begin_src shell
$ telnet 1.2.3.4 80
#+end_src
** Check ISP IP
#+begin_src shell
$ curl ifconfig.co
#+end_src
** Bonding Methods
=balance-rr (0)=: transmit packets in sequential order from the first available slave through the last (provides load-balancing and fault tolerance).

=active-backup=: only one NIC slave in the bond is active, and fallsback to the second slave if the first one fails (provides fault-tolerance).

=balance-xor=: transmit packet based on a hash of the packets source and destination (provides load-balancing and fault tolerance).

=broadcast=: transmit network packets on all slave network interfaces (provides fault tolerance).

=802.3ad, LACP=: aggregation groups that share the same speed and duplex settings. (provides fault tolerance and load-balancing).
** HTTP Method Binaries
=GET=, =HEAD=, etc.. all have binaries symlinked to lsp_request. Like their binary name implies, they can be used to use HTTP methods on a site. For example:

#+begin_src shell
$ HEAD example.gov

# Output
200 OK
Connection: close
Date: Wed, 23 APR 2999 23:18:56 GMT
Accept-Ranges: bytes
ETag: "498-5d8a3050b5915"
Server: WebServer/Dist
Content-Length: 1176
Content-Type: text/html; charset=UTF-8
Last-Modified: Tue, 99 APR 2999 22:39:19 GMT
Client-Date: Wed, 99 APR 2999 23:18:56 GMT
Client-Peer: 1.1.1.1:443
Client-Response-Num: 1
Client-SSL-Cert-Issuer: /C=US/O=Let's Encrypt/CN=R3
Client-SSL-Cert-Subject: /CN=example.gov
Client-SSL-Cipher: TLS_AES_256_GCM_SHA384
Client-SSL-Socket-Class: IO::Socket::SSL
#+end_src

** Check sites HTTP method whitelist
#+begin_src shell
nmap -p443 --script http-methods [IP ADDR]
#+end_src

Output:
#+begin_src
Starting Nmap 6.40 ( http://nmap.org ) at 2019-10-23 08:59 +03
Nmap scan report for <IPAddress>
Host is up (0.0032s latency).
PORT    STATE SERVICE
443/tcp open  https
| http-methods: GET POST OPTIONS HEAD TRACE
| Potentially risky methods: TRACE
|_See http://nmap.org/nsedoc/scripts/http-methods.htmlNmap done: 1 IP address (1 host up) scanned in 0.10 seconds
#+end_src

** netcat
If you want to transmit data over a port, or open a listening connection
#+begin_src shell
echo "something" | nc -l localhsot 61337
#+end_src
* SQL
** Installation
Depending on the system, after installing mariadb/mysql you may need to initialize and start with ~--datadir~ and ~--basedir~:
=mariadb-install-db --user=mysql --basedir=/usr --datadir=/var/lib/mysql=

If you use a non-default location, you can either find it or set it in the [mysqld] section of ~/etc/my.cnf.d/server.cnf~.

Then start with systemd
** Files
~/var/lib/mysql~ needs to have the execute bit set (=chmod u=rwx,g=rwx=), and =mysql:mysql= needs to own the directory.
** Logs
- ~/var/log/mysql~
  If the log isn't here, check the option file (example.cnf). You can grep these variables with:
  =mysqld --help --verbose | grep 'log-error' | tail -1=

- Check option file parameters with:
  =mysqld --print-defaults=

- systemd journal
  =sudo journalctl -u mariadb.service --no-pager=
** General
- =mysql -u root -p=: log in (the password will be blank upon first initil login)

** Create User
#+begin_src sql
CREATE USER 'user'@'localost' IDENTIFIED BY 'some_password';
GRANT ALL PRIVILEGES ON mydb.* TO 'user'@'localhost';
FLUSH PRIVILEGES;
#+end_src

* Web Servers
** apache/httpd
*** Troubleshooting
=systemctl status apache2.service -l --no-pager=: ~-l~ makes sure nothing is truncated

=apachectl configtest=: test the /etc/apache2/apache2.conf configuration
** nginx
=nginx -t=: test nginx configuration
~/logs/error.log~ & ~/logs/access.log~: important log files

*** Security Reference
~server_tokens off~: will disable the nginx + version number on error pages.

~add_header X-Frame-Options "SAMEORIGIN";~: indicates if a browser should be allowed to render a page in a <frame> or an <iframe>. Always set this.

~add_header Strict-Transport-Security "max-age=3156000; includeSubdomains; preload";~: used by websites to declare they should only be accessed via HTTPS. The browser must refuse all HTTP connections and prevent users from accepting insecure SSL certs. (NOTE: the browser caches the STS header for the max-age time, so if you mess up your certs while HSTS you're screwed until you flush the site-data in your browser. This is important because if a user isn't technical they will lose access to your site until they clear their own browser which may never happen within the max-age alloted time). ([[https://www.acunetix.com/blog/articles/what-is-hsts-why-use-it/][Reference]])

~add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;~: Protects the server against certain types of attack including XSS (Cross Site Scripting attacks).

We can limit HTTP methods in the ~location~ directive.
#+begin_src shell
location / {
    limit_except GET HEAD POST { deny all; }
}
#+end_src
*** Load Balancer Reference
| LB Method       | Description                  |
| round-robin     | requests are proxied to host |
|                 | in order they are received   |
| least-connected | requests are proxied to host |
|                 | with least connections       |

#+begin_src shell
http {
    upstream myapp1 {
        server srv1.example.com;
        server srv2.example.com;
        server srv3.example.com;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://myapp1;
        }
    }
}
#+end_src
*** Reverse Proxy Reference
#+begin_src shell
server {                    # Make nginx listen on all ipv4 addys on port 443 (0.0.0.0:443)
                            # ssl specifies that all connections accepted should work in SSL mode
                            # http2 configures port to accept http/2 connections (not exlusively)
    listen                  443 ssl http2;
                            # Make nginx listen on all ipv6 addys on port 443 (dangol'ipv6:443)
    listen                  [::]:443 ssl http2;
    # If you want www, just prepend it i.e. www.server.example.sh, add to HTTP redirect
    # if applicable.
    server_name             servername.example.sh;

    # SSL
    ssl_certificate         /etc/letsencrypt/live/server.example.sh/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/server.example.sh/privkey.pem;
    ssl_trusted_certificate /etc/letsencrypt/live/server.example.sh/chain.pem;

    # You can include relevant configuration files
    include                 extra/security.conf;

    # reverse proxy
    location  {
        # The internal DNS | IP:Port | localhost:port | container_name:port (if applicable)
        proxy_pass http://internal-server-name.nullvoid.rip:6660;
    }

}

# subdomains redirect
# omit this if applicable
server {
    listen                  443 ssl http2;
    listen                  [::]:443 ssl http2;
    # * will redirect all subdomains i.e. music.server.example.sh;
    server_name             *.servername.example.sh;

    # SSL/Paths to letsencrypt keys
    ssl_certificate         /etc/letsencrypt/live/jellyfin.tr909.sh/fullchain.pem;
    ssl_certificate_key     /etc/letsencrypt/live/jellyfin.tr909.sh/privkey.pem;
    ssl_trusted_certificate /etc/letsencrypt/live/jellyfin.tr909.sh/chain.pem;

    return                  301 https://servername.example.sh$request_uri;
}

# HTTP redirect
# Will force HTTPS
server {
    listen      80;
    listen      [::]:80;
    server_name .servername.example.sh;

    location / {
        return 301 https://servername.example.sh$request_uri;
    }
}
#+end_src
* Misc
- =cd -= will switch to the last directory you were in. Fun fact, this trick works with =git= as well.
- In order to open a file named =-=, you have to specify the absolute path (i.e. =cat ./-=)
* Reference
- [[https://github.com/dylanaraps/pure-bash-bible][Pure Bash Bible]]
- [[https://github.com/dylanaraps/pure-sh-bible][Pure POSIX shell Bible]]

* Notes
- TODO: research /proc/process
